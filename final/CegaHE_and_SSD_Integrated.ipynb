{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
            "Collecting numpy>=1.19.3\n",
            "  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
            "\u001b[K     |██████                          | 2.7 MB 9.4 kB/s eta 0:19:591^C\n",
            "\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UU5Bg4DfCCOT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By8G8JD_CF_k",
        "outputId": "f870878f-fa82-4110-d49b-6b8185bb2ffc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UB8IznACH8z",
        "outputId": "5ac22ccc-539c-4e5f-db58-3e4003e367fc"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMoS4FDbCKcd",
        "outputId": "5c80d64c-acb0-4796-c7c0-a32cee284aa7"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (582254286.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    cd models/research\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python3 -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w4tcnKz3qlb0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scipy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import scipy.misc\n",
        "import six\n",
        "import time\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import visualization_utils as viz_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI21ZMbACrfI"
      },
      "outputs": [],
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path (this can be local or on colossus)\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Load the COCO Label Map\n",
        "category_index = {\n",
        "    1: {'id': 1, 'name': 'person'}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04XscfakVxkJ",
        "outputId": "6b7ed819-8dea-4056-c2f1-8c2a1e5cff63"
      },
      "outputs": [],
      "source": [
        "# Download the saved model and put it into models/research/object_detection/test_data/\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "!tar -xf ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "!mv ssd_mobilenet_v2_320x320_coco17_tpu-8/ models/research/object_detection/test_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6UYGqtQVyOV",
        "outputId": "7a4f314b-afb2-4791-8f90-fbe5e7920962"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "detect_fn = tf.saved_model.load('models/research/object_detection/test_data/ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU7sWVKyutQG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "\n",
        "# Assuming you have a detect_human function\n",
        "def detect_human(image_np):\n",
        "    input_tensor = np.expand_dims(image_np, 0)\n",
        "    start_time = time.time()\n",
        "    detections = detect_fn(input_tensor)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    # Filter and keep only 'person' class detections\n",
        "    person_indices = np.where(\n",
        "        (detections['detection_classes'][0].numpy() == category_index[1]['id']) &\n",
        "        (detections['detection_scores'][0].numpy() > 0.5)\n",
        "    )\n",
        "    person_boxes = detections['detection_boxes'][0].numpy()[person_indices]\n",
        "    person_classes = detections['detection_classes'][0].numpy()[person_indices]\n",
        "    person_scores = detections['detection_scores'][0].numpy()[person_indices]\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        person_boxes,\n",
        "        person_classes.astype(np.int32),\n",
        "        person_scores,\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.40,\n",
        "        agnostic_mode=False\n",
        "    )\n",
        "\n",
        "    return image_np_with_detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DVMUfPPbV0En",
        "outputId": "cca2a90f-95af-419c-d240-92d58490131b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "data_dir = '/content/drive/Shareddrives/fyp/Datasets/Custom Dataset'\n",
        "\n",
        "images = os.listdir(f\"{data_dir}/Low light 4\")\n",
        "images = sorted(images, reverse=True)\n",
        "print(images)\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12, 12))\n",
        "\n",
        "# Assuming you have a detect_human function\n",
        "def detect_human(image_np):\n",
        "    input_tensor = np.expand_dims(image_np, 0)\n",
        "    start_time = time.time()\n",
        "    detections = detect_fn(input_tensor)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    # Filter and keep only 'person' class detections\n",
        "    person_indices = np.where(\n",
        "        (detections['detection_classes'][0].numpy() == category_index[1]['id']) &\n",
        "        (detections['detection_scores'][0].numpy() > 0.5)\n",
        "    )\n",
        "    person_boxes = detections['detection_boxes'][0].numpy()[person_indices]\n",
        "    person_classes = detections['detection_classes'][0].numpy()[person_indices]\n",
        "    person_scores = detections['detection_scores'][0].numpy()[person_indices]\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        person_boxes,\n",
        "        person_classes.astype(np.int32),\n",
        "        person_scores,\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.40,\n",
        "        line_thickness=8,\n",
        "        agnostic_mode=False\n",
        "    )\n",
        "\n",
        "    return image_np_with_detections\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(len(images),2,figsize=(16, 16))\n",
        "# Example usage:\n",
        "for i in range(len(images)):\n",
        "\n",
        "    image = cv2.imread(f'{data_dir}/Low light 4/{images[i]}')\n",
        "\n",
        "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "\n",
        "\n",
        "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    equalized_image = cv2.equalizeHist(gray_img)\n",
        "\n",
        "    hist1 = cv2.calcHist([equalized_image], [0], None, [256], [0, 256])\n",
        "\n",
        "    enhanced_image = clahe.apply(equalized_image)\n",
        "    clahe_image = clahe.apply(gray_img)\n",
        "    hist2 = cv2.calcHist([clahe_image], [0], None, [256], [0, 256])\n",
        "\n",
        "    enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
        "    axes[i-3,0].imshow(cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Assuming you have 'detect_fn' and 'category_index' defined somewhere\n",
        "    result_image = detect_human(enhanced_image)\n",
        "    axes[i-3,1].imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Ensure the layout is properly managed\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNrCJ33IKIaL",
        "outputId": "018e965a-edef-4c49-af6d-03952fdf3219"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(12, 12))\n",
        "\n",
        "\n",
        "def enhance_video(input_video_path, output_video_path):\n",
        "    # Read the video\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(fps,frame_count)\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "    i = 0\n",
        "    while i < 5:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "        gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        equalized_image = cv2.equalizeHist(gray_img)\n",
        "\n",
        "        enhanced_image = clahe.apply(equalized_image)\n",
        "        enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Assuming you have 'detect_fn' and 'category_index' defined somewhere\n",
        "        result_image = detect_human(enhanced_image)\n",
        "\n",
        "        if i < 5:\n",
        "          print(i)\n",
        "          axes[i,0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "          axes[i,1].imshow(cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB))\n",
        "          axes[i,2].imshow(cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2RGB))\n",
        "          axes[i,3].imshow(cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # Enhance the frame\n",
        "\n",
        "        # Write the frame into the file\n",
        "        # out.write(result_image)\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    # Release everything\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(5,4,figsize=(8, 10))\n",
        "\n",
        "# Example usage\n",
        "input_video_path = 'IMG_4514.MOV'\n",
        "output_video_path = 'IMG_4514_enhanced.mp4'\n",
        "start_time = time.time()\n",
        "enhance_video(input_video_path, output_video_path)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Elapsed time: ' + str(elapsed_time) + 's')\n",
        "# Ensure the layout is properly managed\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
