{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers, metrics\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplets(directory, img_per_class=None):\n",
    "    triplets = []\n",
    "    folders = os.listdir(directory)\n",
    "    try:\n",
    "        folders.remove(\".DS_Store\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    for folder in folders[:50]:\n",
    "\n",
    "        path = os.path.join(directory, folder)\n",
    "        files = os.listdir(path)\n",
    "        try:\n",
    "            files.remove(\".DS_Store\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "\n",
    "        # Creating training triplets\n",
    "        for anchor_file in files[:img_per_class]:\n",
    "            positive_file = random.choice([file for file in files if file != anchor_file])\n",
    "            negative_folder = random.choice([f for f in folders[:10] if f != folder])\n",
    "            negative_images = os.listdir(os.path.join(directory, negative_folder))\n",
    "            try:\n",
    "                negative_images.remove(\".DS_Store\")\n",
    "            except ValueError:\n",
    "                pass\n",
    "            negative_file = random.choice(negative_images)\n",
    "            triplets.append(((folder, anchor_file), (folder, positive_file), (negative_folder, negative_file)))\n",
    "\n",
    "    random.shuffle(triplets)\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seeds to enable consistency while testing.\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "ROOT = 'dataset'\n",
    "def read_image(path):\n",
    "    image_1 = cv2.imread(path)\n",
    "    image = cv2.resize(image_1, (128, 128))\n",
    "\n",
    "    if image is not None:\n",
    "        return image\n",
    "    else:\n",
    "        print(f\"Error: Unable to load image at path {path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(input_shape):\n",
    "    \"\"\" Returns the image encoding model \"\"\"\n",
    "\n",
    "    pretrained_model = Xception(\n",
    "        input_shape=input_shape,\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "    )\n",
    "    print(len(pretrained_model.layers))\n",
    "\n",
    "    for i in range(len(pretrained_model.layers)-27):\n",
    "        pretrained_model.layers[i].trainable = False\n",
    "\n",
    "    encode_model = Sequential([\n",
    "        pretrained_model,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "    ], name=\"Encode_Model\")\n",
    "\n",
    "    print(len(encode_model.layers))\n",
    "    return encode_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "def get_siamese_network(input_shape = (128, 128, 3)):\n",
    "    encoder = get_encoder(input_shape)\n",
    "\n",
    "    # Input Layers for the images\n",
    "    anchor_input   = layers.Input(input_shape, name=\"Anchor_Input\")\n",
    "    positive_input = layers.Input(input_shape, name=\"Positive_Input\")\n",
    "    negative_input = layers.Input(input_shape, name=\"Negative_Input\")\n",
    "\n",
    "    ## Generate the encodings (feature vectors) for the images\n",
    "    encoded_a = encoder(anchor_input)\n",
    "    encoded_p = encoder(positive_input)\n",
    "    encoded_n = encoder(negative_input)\n",
    "\n",
    "    # A layer to compute ‖f(A) - f(P)‖² and ‖f(A) - f(N)‖²\n",
    "    distances = DistanceLayer()(\n",
    "        encoder(anchor_input),\n",
    "        encoder(positive_input),\n",
    "        encoder(negative_input)\n",
    "    )\n",
    "\n",
    "    # Creating the Model\n",
    "    siamese_network = Model(\n",
    "        inputs  = [anchor_input, positive_input, negative_input],\n",
    "        outputs = distances,\n",
    "        name = \"Siamese_Network\"\n",
    "    )\n",
    "    return siamese_network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SiameseModel(Model):\n",
    "    # Builds a Siamese model based on a base-model\n",
    "    def __init__(self, siamese_network, margin=1.0):\n",
    "        super(SiameseModel, self).__init__()\n",
    "\n",
    "        self.margin = margin\n",
    "        self.siamese_network = siamese_network\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        # Get the two distances from the network, then compute the triplet loss\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics so the reset_states() can be called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_encoder(model):\n",
    "    encoder = get_encoder((128, 128, 3))\n",
    "    i=0\n",
    "    for e_layer in model.layers[0].layers[3].layers:\n",
    "        layer_weight = e_layer.get_weights()\n",
    "        encoder.layers[i].set_weights(layer_weight)\n",
    "        i+=1\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_batch(triplet_list, data_type, batch_size=4, preprocess=True):\n",
    "    batch_steps = len(triplet_list)//batch_size\n",
    "\n",
    "    for i in range(batch_steps+1):\n",
    "        anchor   = []\n",
    "        positive = []\n",
    "        negative = []\n",
    "\n",
    "        j = i*batch_size\n",
    "        while j<(i+1)*batch_size and j<len(triplet_list):\n",
    "            a, p, n = triplet_list[j]\n",
    "            # print(a,p,n)\n",
    "            anchor.append(read_image(f'faces_ds/{data_type}/{a[0]}/{a[1]}'))\n",
    "            positive.append(read_image(f'faces_ds/{data_type}/{p[0]}/{p[1]}'))\n",
    "            negative.append(read_image(f'faces_ds/{data_type}/{n[0]}/{n[1]}'))\n",
    "            j+=1\n",
    "\n",
    "        anchor = np.array(anchor)\n",
    "        positive = np.array(positive)\n",
    "        negative = np.array(negative)\n",
    "\n",
    "        if preprocess:\n",
    "            anchor = preprocess_input(anchor)\n",
    "            positive = preprocess_input(positive)\n",
    "            negative = preprocess_input(negative)\n",
    "\n",
    "        yield ([anchor, positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_triplets(batch_size = 4):\n",
    "    pos_scores, neg_scores = [], []\n",
    "\n",
    "    for data in get_custom_batch(validation_triplet, 'validation',batch_size=batch_size):\n",
    "        prediction = siamese_model.predict(data)\n",
    "        # print(prediction)\n",
    "        pos_scores += list(prediction[0])\n",
    "        neg_scores += list(prediction[1])\n",
    "\n",
    "    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n",
    "    ap_mean = np.mean(pos_scores)\n",
    "    an_mean = np.mean(neg_scores)\n",
    "    ap_stds = np.std(pos_scores)\n",
    "    an_stds = np.std(neg_scores)\n",
    "\n",
    "    print(f\"Accuracy on validation = {accuracy:.5f}\")\n",
    "    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\n",
      "193\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "train_triplet = create_triplets(\"faces_ds/train\")\n",
    "validation_triplet = create_triplets(\"faces_ds/validation\")\n",
    "# validation_triplet = create_triplets(\"dataset/validation\", 10)\n",
    "# train_triplet.extend(validation_triplet)\n",
    "\n",
    "print(len(train_triplet))\n",
    "print(len(validation_triplet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "8\n",
      "Model: \"Siamese_Network\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Anchor_Input (InputLayer)      [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Positive_Input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Negative_Input (InputLayer)    [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Encode_Model (Sequential)      (None, 256)          22043944    ['Anchor_Input[0][0]',           \n",
      "                                                                  'Positive_Input[0][0]',         \n",
      "                                                                  'Negative_Input[0][0]']         \n",
      "                                                                                                  \n",
      " distance_layer (DistanceLayer)  ((None,),           0           ['Encode_Model[3][0]',           \n",
      "                                 (None,))                         'Encode_Model[4][0]',           \n",
      "                                                                  'Encode_Model[5][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,043,944\n",
      "Trainable params: 9,583,800\n",
      "Non-trainable params: 12,460,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_network = get_siamese_network()\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded successfully.\n",
      "133\n",
      "8\n",
      "Model: \"Encode_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 2048)              20861480  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,043,944\n",
      "Trainable params: 9,583,800\n",
      "Non-trainable params: 12,460,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.001)\n",
    "\n",
    "siamese_model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Path to the saved weights\n",
    "weights_path = \"second_training/siamese_best_acc_model_custom_best_acc\"\n",
    "\n",
    "# Load the previously saved weights\n",
    "siamese_model.load_weights(weights_path)\n",
    "\n",
    "print(\"Weights loaded successfully.\")\n",
    "\n",
    "\n",
    "best_acc_encoder = extract_encoder(siamese_model)\n",
    "best_acc_encoder.save_weights(\"second_training/best_acc_encoder\")\n",
    "best_acc_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_path = '/content/drive/Shareddrives/fyp/Datasets/Custom Dataset/Faces/val'\n",
    "test_path = '/content/drive/Shareddrives/fyp/Datasets/Custom Dataset/Faces/test'\n",
    "folders = os.listdir(validation_path)\n",
    "\n",
    "\n",
    "print(folders)\n",
    "\n",
    "all_average_distances = {}\n",
    "\n",
    "for class_folder in folders:\n",
    "\n",
    "    class_path = os.path.join(validation_path, class_folder)\n",
    "    files = os.listdir(class_path)\n",
    "    all_average_distances[class_folder] = []\n",
    "\n",
    "    for image in files:\n",
    "        image_path1 = os.path.join(class_path, image)\n",
    "        image1, _,_ = preprocess_image(image_path1, 0)\n",
    "        embedding1 = encoder.predict(image1)\n",
    "\n",
    "        average_distances = {}\n",
    "\n",
    "        for i, folder in enumerate(folders, start=0):\n",
    "\n",
    "          test_class_path = os.path.join(test_path, folder)\n",
    "          files = os.listdir(test_class_path)\n",
    "\n",
    "          distances = []\n",
    "\n",
    "          for j in range(5):\n",
    "            random_file = random.choice(files)\n",
    "            file_path = os.path.join( test_class_path, random_file)\n",
    "            image2, _,_ = preprocess_image(file_path,0)\n",
    "\n",
    "            embedding2 = encoder.predict(image2)\n",
    "            distance = np.linalg.norm(embedding1 - embedding2)\n",
    "            distances.append(distance)\n",
    "\n",
    "          # axs[i , 0].imshow(cv2.cvtColor(cv2.imread(image_path1), cv2.COLOR_BGR2RGB))\n",
    "          # axs[i , 1].imshow(cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "          # Calculate the average distance for the current class\n",
    "          average_distance = np.mean(distances)\n",
    "\n",
    "          average_distances[folder] = average_distance\n",
    "          # Add the average distance as a label on the corresponding image plot on the right\n",
    "        print(average_distances)\n",
    "\n",
    "        all_average_distances[class_folder].append(average_distances)\n",
    "\n",
    "        # # Determine if the minimum average distance is less than 1.5\n",
    "        # if min(average_distances.values()) < 1.5:\n",
    "        #     result = False\n",
    "        # else:\n",
    "        #     result = True\n",
    "\n",
    "        # print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
